{
  "hash": "d07d24e8787f089f673defb617e650e8",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"The air in the AI bubble may be leaking\"\nauthor: \"Jason Bryer\"\ndate: 2025-12-02\ndraft: false\ndescription: \"\"\ncategories: [\"AI\"]\nimage: \"2025-12-02-The_air_in_the_AI_bubble_is_leaking.png\"\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n\n::: {.cell}\n\n:::\n\n\n*Note: This is a longer version of an OpEd published in the [CUNY SPS Magazine](https://sps.cuny.edu/about/dean/cuny-sps-magazine)*\n\n\nSince the release of ChatGPT in late 2022, “Artificial Intelligence” (AI) has entered the general psyche often being pitched as either an existential crisis (see e.g. [Bender, Gebru, McMillian-Major, & Mitchell, 2021](https://dl.acm.org/doi/10.1145/3442188.3445922)) or the technology that will replace humans as predicted by Bill Gates. The problem with understanding the true impact of AI (hint: the answer is almost always in the middle), is that the term itself has no technical merit and is simply a marketing term. Broadly speaking, AI refers to one of two technologies: predictive modeling or large language models (LLM). We have been doing the former for at least a century. The basic regression techniques often taught in high school are a form of predictive modeling. Over the last few centuries with the wide availability of computers, predictive modeling has certainly become more sophisticated. However, it is the LLMs that is causing the disruption. The release of the transformers paper changed how we convert text into numbers. Let's be clear, computers do not understand language. They are merely finding patterns and connections between numeric representations of language. What OpenAI discovered (much to their own surprise) is that when you train models with increasing large datasets the patterns seemingly mimic human conversation. \n\nI will admit, the results from chat bots are incredible. But so was David Copperfield making the Statue of Liberty disappear. OpenAI has a principal similar to Moore's Law (which is the principle that computers will double in speed every 2 years) that the number of parameters in their models (like number of words) will grow at a rate larger than Moore's Law. We are currently starting to see the end of Moore's Law as we reach the physical limit of how small we can make transistors. Consider that OpenAI is already using virtually all written materials to train their models, how much can they grow? We may already be seeing a plateau with the release of ChatGPT 5 which was released to lackluster reviews, with many arguing they may have step backwards.\n\nI'm not naive, AI will change things. But it will change things more akin to how spreadsheets, spell check, and calculators changed the world. Some industries will change more than others. I have been using predictive modeling and LLMs in my own research on college readiness and what I have found is that smaller, more targeted uses are more effective than larger, more generalized models. And it has allowed us to solve problems we would have been unsolved without these technologies. \n\nMy hope is that current AI bubble deflates a bit so we can move beyond the hype and have serious conversations about how these technologies can be more effectively used to benefit humans and not replace us.\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}