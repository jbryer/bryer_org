{
  "hash": "772450342661f72b71404bdf9666248e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Why you should not use mean imputation for missing data\"\nauthor: \"Jason Bryer\"\ndate: 2025-11-18\ndraft: false\ndescription: \"\"\ncategories: [\"R\"]\nimage: \"2025-10-22-SAT_ACT_Requirements.png\"\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n\n::: {.cell}\n\n:::\n\n\nI encountered the question today of what to do with missing values when conducting null hypothesis testing or regression? I have seen many suggest doing mean imputation. That is, simply replace any missing values with the mean of the variable calculated from the observed values. I argue that mean imputation is worse than doing nothing. Let's explore.\n\nTo begin, let's simulate a vector, `x`, from the random normal distribution.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(2112)\nx <- rnorm(100, mean = 0, sd = 1)\n(mean1 <- mean(x))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.01129628\n```\n\n\n:::\n\n```{.r .cell-code}\n(sd1 <- sd(x))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.032159\n```\n\n\n:::\n:::\n\n\nWe can see that the mean and standard deviation aver fairly close to 0 and 1, respectively. In the next code chunk we are going to randomly select 20% of observations and set the value to `NA`. We can calculate the mean and standard deviation excluding the missing values (i.e. `NA`s) but setting `na.rm = TRUE`. The mean and standard deviation are relatively close.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx[sample(length(x), length(x) * 0.2, replace = FALSE)] <- NA\n(mean2 <- mean(x, na.rm = TRUE))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.02136184\n```\n\n\n:::\n\n```{.r .cell-code}\n(sd2 <- sd(x, na.rm = TRUE))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.071757\n```\n\n\n:::\n:::\n\n\nNow we will replace the `NA`s we introduced above with the mean. We can see that the standard deviation is quite a bit smaller, hence reducing the variance of our estimate. Since many of our statistical tests rely on variance, reducing the variance may lead to spurious conclusions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx[is.na(x)] <- mean(x, na.rm = TRUE)\n(mean3 <- mean(x))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.02136184\n```\n\n\n:::\n\n```{.r .cell-code}\n(sd3 <- sd(x))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.9573977\n```\n\n\n:::\n:::\n\n\nTo show this is not a random anomaly for our one random sample, let's repeat the above 1,000 times.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_samples <- 1000\npercent_missing <- 0.10\nsd_diffs <- data.frame(sample = 1:n_samples,\n\t\t\t\t\t   sd_drop_miss = numeric(n_samples),\n\t\t\t\t\t   sd_impute_miss = numeric(n_samples))\nfor(i in seq_len(n_samples)) {\n\tx2 <- x\n\tx2[sample(length(x), length(x) * percent_missing, replace = FALSE)] <- NA\n\tsd_diffs[i,]$sd_drop_miss <- sd(x2, na.rm = TRUE)\n\tx2[is.na(x2)] <- mean(x2, na.rm = TRUE)\n\tsd_diffs[i,]$sd_impute_miss <- sd(x2)\n}\n\nsd_diffs |> \n\treshape2::melt(id.vars = 'sample', variable.name = 'calculation_type', value.name = 'sd') |>\n\tggplot(aes(x = sd, color = calculation_type)) +\n\t\tgeom_vline(xintercept = sd(x)) +\n\t\tgeom_density() +\n\t\txlab('Standard Deviation') +\n\t\ttheme_minimal()\n```\n\n::: {.cell-output-display}\n![](2025-11-18-Do_not_use_mean_imputation_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nAs the figure above shows, there is a significant difference in the standard deviation estimates when calculated using only observed values and calculated with missing values imputed with the mean. The *t*-test below confirms this.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(sd_diffs$sd_drop_miss, sd_diffs$sd_impute_miss)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWelch Two Sample t-test\n\ndata:  sd_diffs$sd_drop_miss and sd_diffs$sd_impute_miss\nt = 54.288, df = 1992.4, p-value < 2.2e-16\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 0.04782442 0.05140925\nsample estimates:\nmean of x mean of y \n0.9569447 0.9073278 \n```\n\n\n:::\n:::\n\n\nNow let's consider how mean imputation can impact the estimation of a correlation between two variables. We will simulate two variables with a population correlation of 0.18.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 100\nmean_x <- 0\nmean_y <- 0\nsd_x <- 1\nsd_y <- 1\nrho <- 0.18\n\nset.seed(2112)\ndf <- mvtnorm::rmvnorm(\n\tn = 100,\n\tmean = c(mean_x, mean_y),\n\tsigma = matrix(c(sd_x^2, rho * (sd_x * sd_y),\n\t\t\t\t\t rho * (sd_x * sd_y), sd_y^2), 2, 2)) |>\n\tas.data.frame() |>\n\tdplyr::rename(x = V1, y = V2)\n\ncor.test(df$x, df$y)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's product-moment correlation\n\ndata:  df$x and df$y\nt = 1.8314, df = 98, p-value = 0.07008\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.01504323  0.36527878\nsample estimates:\n      cor \n0.1819124 \n```\n\n\n:::\n:::\n\n\nWe will now randomly select 20% of `x` values to set to `NA`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_miss <- df\ndf_miss[sample(n, size = 0.2 * n, replace = FALSE),]$x <- NA\ncor.test(df_miss$x, df_miss$y)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's product-moment correlation\n\ndata:  df_miss$x and df_miss$y\nt = 1.8392, df = 78, p-value = 0.06969\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.01658176  0.40543327\nsample estimates:\n      cor \n0.2038779 \n```\n\n\n:::\n:::\n\n\nNote that the *p*-value for both the correlation estimated using the complete dataset and estimated with observed values only is greater than 0.05 (i.e. we would fail to reject the null that the correlation is 0).\n\nNow we will impute the missing values with the mean and calcualte the correlation.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_miss[is.na(df_miss$x),] <- mean(df$x, na.rm = TRUE)\ncor.test(df_miss$x, df_miss$y)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's product-moment correlation\n\ndata:  df_miss$x and df_miss$y\nt = 2.0582, df = 98, p-value = 0.04223\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.007431517 0.384594022\nsample estimates:\n      cor \n0.2035525 \n```\n\n\n:::\n:::\n\n\nWe would now reject the null and conclude that there is a statistically significant correlation between `x` and `y` even though our original dataset from which this was simulated was not. \n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}