{
  "hash": "92be4ef8d0a00e5736205f6b46694ffa",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Sample size and statistical significance for chi-squared tests\"\nauthor: \"Jason Bryer\"\ndate: 2025-03-04\ndraft: false\ndescription: \"\"\ncategories: [\"R\", \"Statistics\"]\nimage: \"2025-03-04-chi_squared_sample_sizes.png\"\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\nIn this post we are going to explore the relationship between sample size (*n*) and statistical significance for the chi-squared ($\\chi^2$) test. Recall that from the normal distribution, we construct a confidence interval using:\n\n$$ CI = \\bar{x} \\pm z \\cdot SE$$\n\nwhere *z* is the test statistic and:\n\n$$ SE =  \\frac{s}{\\sqrt{n}} $$\n\nwhere *s* is the sample standard deviation. Typically our *null* is zero in which case we reject the *null* hypothesis when the confidence does not span zero. If we wish to construct a 95% confidence interval, then $z = 1.96$. Assuming the sample standard deviation is constant regardless of sample size (a fair assumption), then as *n* increases the standard error decreases. The following calculates the confidence interval for *n* ranging from 10 to 400 assuming a sample standard deviation of 0.15 and 95% confidence level. When $n > 171$ then $p < 0.05$.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define some parameters\nsig_level <- .95  # Significance level, 95% here\nes <- 0.15        # Effect size in standard units\nnull_val <- 0     # null value\n\n#' Calculate the standard error\n#' \n#' This function will calculate the standard error from a vector of observations or with a given\n#' sample standard deviation and sample size.\n#' \n#' @param x numeric vector of observations.\n#' @param sigma the sample standard deviation.\n#' @param n sample size.\nstandard_error <- function(x, sigma = sd(x), n = length(x)) {\n\tif(!missing(x)) { # Some basic error checking\n\t\tif(sigma != sd(x)) { warning('The sample standard deviation (sigma) is not equal to sd(x)')}\n\t\tif(n != length(x)) { warning('The sample size (n) is not equal to length(x).' )}\n\t}\n\treturn(sigma / sqrt(n))\n}\n# Create a data.frame with varying sample sizes and the corresponding standard error\ndf <- data.frame(\n\tn = 10:400,\n\tse = standard_error(sigma = 1, n = 10:400)\n)\ncv <- abs(qnorm((1 - sig_level) / 2)) # Critical value (z test statistic)\ndf$ci_low <- es - cv * df$se\ndf$ci_high <- es + cv * df$se\ndf$sig <- null_val < df$ci_low | null_val > df$ci_high\nmin_n <- df$n[df$sig] |> min()\nggplot(df, aes(x = n, y = se, color = sig)) + \n\tgeom_path() +\n\tgeom_point() +\n\tscale_color_brewer(paste0('p < ', (1 - sig_level)), type = 'qual', palette = 6) +\n\tggtitle(paste0('Minumum n for p < ', (1 - sig_level), ': ', min_n),\n\t\t\tsubtitle = paste0('effect size: ', es, '; null value: ', null_val))\n```\n\n::: {.cell-output-display}\n![](2025-03-04-chi_squared_sample_sizes_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\n\nThe chi-squared ($\\chi^2$) test statistic is defined as:\n\n$$ \\chi^2 = \\sum{\\frac{(O - E)^2}{E}} $$\n\nwhere *O* is the observed count and *E* is the expected count. Unlike the standard error for numerical data, *n* is not explicitly in the formula and therefore makes it a bit more challenging to determine the impact sample size has rejecting the *null* hypothesis. Moreover, since the chi-squared is calculated from the cell counts in a table of varying length and dimension (one- or two-dimensions specifically) determining how *n* impacts rejecting the *null* or not requires more parameters. \n\nAnswering the question of how large does *n* need to be to detect a statistically significant result (i.e. to reject the *null* hypothesis) is refereed to as [power](https://en.wikipedia.org/wiki/Power_(statistics)). Whereas for calculating the power for numerical data had one parameter, the sample standard deviation, here we need to consider the proportion of observations within different cells. For example, consider we have a variable with three levels and we expect the proportion of observations in the three groups to be 33%, 25%, and 42%, respectively. If our sample size is 100 then we expect there to be 33, 25, and 42 and observations for the three categories. This function will, for varying sample sizes, calculate the counts for the categories to achieve that sample size, estimate the chi-squared statistic and record the *p*-value. There are other parameters that are documented below. A `plot` function is also defined using the [S3 objected oriented framework](http://adv-r.had.co.nz/S3.html).\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#' Calculate p-value from a chi-squared test with varying sample sizes\n#'\n#' This algorithm will start with an initial sample size (`n_start`) and perform a chi-squared test\n#' with a vector of counts equal to `n * probs`. This will repeat increasing the sample size by\n#' `n_step` until the p-value from the chi-squared test is less than `p_stop`.\n#'\n#' @param vector of cell probabilities. The sum of the values must equal 1.\n#' @param sig_level significance level.\n#' @param p_stop the p-value to stop estimating chi-squared tests.\n#' @param max_n maximum n to attempt if `p_value` is never less than `p_stop`.\n#' @param min_cell_size minimum size per cell to perform the chi-square test.\n#' @param n_start the starting sample size.\n#' @param n_step the increment for each iteration.\n#' @return a data.frame with three columns: n (sample size), p_value, and sig (TRUE if\n#'         p_value < sig_level).\n#' @importFrom DescTools power.chisq.test CramerV\nchi_squared_power <- function(\n\t\tprobs,\n\t\tsig_level = 0.05,\n\t\tp_stop = 0.01,\n\t\tpower = 0.80,\n\t\tpower_stop = 0.90,\n\t\tmax_n = 100000,\n\t\tmin_cell_size = 10,\n\t\tn_start = 10,\n\t\tn_step = 10\n) {\n\tif(sum(probs) != 1) { # Make sure the sum is equal to 1\n\t\tstop('The sum of the probabilities must equal 1.')\n\t} else if(length(unique(probs)) == 1) {\n\t\tstop('All the probabilities are equal.')\n\t}\n\n\tn <- n_start\n\tp_values <- numeric()\n\tpower_values <- numeric()\n\tdf <- ifelse(is.vector(probs),\n\t\t\t\t length(probs) - 1,\n\t\t\t\t min(dim(probs)) - 1) # Degrees of freedom\n\trepeat {\n\t\tx <- (probs * n) |> round()\n\t\tif(all(x > min_cell_size)) {\n\t\t\tcs <- chisq.test(x, rescale.p = TRUE, simulate.p.value = FALSE)\n\t\t\tp_values[n / n_step] <- cs$p.value\n\t\t\tpow <- DescTools::power.chisq.test(\n\t\t\t\tn = n,\n\t\t\t\tw = DescTools::CramerV(as.table(x)),\n\t\t\t\tdf = df,\n\t\t\t\tsig.level = sig_level\n\t\t\t)\n\t\t\tpower_values[n / n_step] <- pow$power\n\t\t\tif((cs$p.value < p_stop & pow$power > power_stop) | n > max_n) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else {\n\t\t\tp_values[n / n_step] <- NA\n\t\t\tpower_values[n / n_step] <- NA\n\t\t}\n\t\tn <- n + n_step\n\t}\n\tresult <- data.frame(n = seq(10, length(p_values) * n_step, n_step),\n\t\t\t\t\t\t p_value = p_values,\n\t\t\t\t\t\t sig = p_values < sig_level,\n\t\t\t\t\t\t power = power_values)\n\tclass(result) <- c('chisqpower', 'data.frame')\n\tattr(result, 'probs') <- probs\n\tattr(result, 'sig_level') <- sig_level\n\tattr(result, 'p_stop') <- p_stop\n\tattr(result, 'power') <- power\n\tattr(result, 'power_stop') <- power_stop\n\tattr(result, 'max_n') <- max_n\n\tattr(result, 'n_step') <- n_step\n\treturn(result)\n}\n\n#' Plot the results of chi-squared power estimation\n#'\n#' @param x result of [chi_squared_power()].\n#' @param plot_power whether to plot the power curve.\n#' @param plot_p whether to plot p-values.\n#' @param digits number of digits to round to.\n#' @param segement_color color of the lines marking where power and p values exceed threshold.\n#' @param sgement_linetype linetype of the lines marking where power and p values exceed threshold.\n#' @param p_linetype linetype for the p-values.\n#' @param power_linetype linetype for the power values.\n#' @param title plot title. If missing a title will be automatically generated.\n#' @parma ... currently not used.\n#' @return a ggplot2 expression.\nplot.chisqpower <- function(\n\t\tx,\n\t\tplot_power = TRUE,\n\t\tplot_p = TRUE,\n\t\tdigits = 4,\n\t\tsegment_color = 'grey60',\n\t\tsegment_linetype = 1,\n\t\tp_linetype = 1,\n\t\tpower_linetype = 2,\n\t\ttitle,\n\t\t...\n) {\n\tpow <- attr(x, 'power')\n\n\tp <- ggplot(x[!is.na(x$p_value),], aes(x = n, y = p_value))\n\n\tif(plot_power) {\n\t\tif(any(x$power > pow, na.rm = TRUE)) {\n\t\t\tmin_n_power <- min(x[x$power > pow,]$n, na.rm = TRUE)\n\t\t\tp <- p +\n\t\t\t\tgeom_segment(\n\t\t\t\t\tx = 0,\n\t\t\t\t\txend = min_n_power,\n\t\t\t\t\ty = pow,\n\t\t\t\t\tyend = pow,\n\t\t\t\t\tcolor = segment_color,\n\t\t\t\t\tlinetype = segment_linetype) +\n\t\t\t\tggplot2::annotate(\n\t\t\t\t\tgeom = 'text',\n\t\t\t\t\tx = 0,\n\t\t\t\t\ty =  pow,\n\t\t\t\t\tlabel = paste0('Power = ',  pow),\n\t\t\t\t\tvjust = -1,\n\t\t\t\t\thjust = 0) +\n\t\t\t\tgeom_segment(\n\t\t\t\t\tx = min_n_power,\n\t\t\t\t\txend = min_n_power,\n\t\t\t\t\ty = pow,\n\t\t\t\t\tyend = 0,\n\t\t\t\t\tcolor = segment_color,\n\t\t\t\t\tlinetype = segment_linetype) +\n\t\t\t\tggplot2::annotate(\n\t\t\t\t\tgeom = 'text',\n\t\t\t\t\tx = min_n_power, y = 0,\n\t\t\t\t\tlabel = paste0('n = ', prettyNum(min_n_power, big.mark = ',')),\n\t\t\t\t\tvjust = 1,\n\t\t\t\t\thjust = -0.1)\n\t\t}\n\t\tp <- p +\n\t\t\tgeom_path(\n\t\t\t\taes(y = power),\n\t\t\t\tcolor = '#7570b3',\n\t\t\t\tlinetype = power_linetype)\n\t}\n\tif(plot_p) {\n\t\tif(any(x$sig, na.rm = TRUE)) {\n\t\t\tp <- p +\n\t\t\t\tgeom_segment(\n\t\t\t\t\tx = 0,\n\t\t\t\t\txend = min(x[x$sig,]$n, na.rm = TRUE),\n\t\t\t\t\ty = attr(x, 'sig_level'),\n\t\t\t\t\tyend = attr(x, 'sig_level'),\n\t\t\t\t\tcolor = segment_color,\n\t\t\t\t\tlinetype = segment_linetype) +\n\t\t\t\tggplot2::annotate(\n\t\t\t\t\tgeom = 'text',\n\t\t\t\t\tx = 0,\n\t\t\t\t\ty =  attr(x, 'sig_level'),\n\t\t\t\t\tlabel = paste0('p = ',  attr(x, 'sig_level')),\n\t\t\t\t\tvjust = -1,\n\t\t\t\t\thjust = 0) +\n\t\t\t\tgeom_segment(\n\t\t\t\t\tx = min(x[x$sig,]$n, na.rm = TRUE),\n\t\t\t\t\txend = min(x[x$sig,]$n, na.rm = TRUE),\n\t\t\t\t\ty = attr(x, 'sig_level'),\n\t\t\t\t\tyend = 0,\n\t\t\t\t\tcolor = segment_color,\n\t\t\t\t\tlinetype = segment_linetype) +\n\t\t\t\tggplot2::annotate(\n\t\t\t\t\tgeom = 'text',\n\t\t\t\t\tx = min(x[x$sig,]$n, na.rm = TRUE),\n\t\t\t\t\ty = 0,\n\t\t\t\t\tlabel = paste0('n = ', prettyNum(min(x[x$sig,]$n, na.rm = TRUE), big.mark = ',')),\n\t\t\t\t\tvjust = 1,\n\t\t\t\t\thjust = -0.1)\n\t\t}\n\t\tp <- p +\n\t\t\tgeom_path(\n\t\t\t\talpha = 0.7,\n\t\t\t\tlinetype = p_linetype)\n\t\t\t# geom_point(aes(color = sig), size = 1) +\n\t\t\t# scale_color_brewer(paste0('p < ', attr(x, 'sig_level')), type = 'qual', palette = 6)\n\t}\n\n\tif(missing(title)) {\n\t\tif(any(x$power > pow, na.rm = TRUE) & any(x$sig, na.rm = TRUE)) {\n\t\t\tmin_n <- min(x[x$sig & x$power > pow,]$n, na.rm = TRUE)\n\t\t\ttitle <- paste0('Smallest n where p < ', attr(x, 'sig_level'), ' and power > ', pow, ': ',\n\t\t\t\t\t\t\tprettyNum(min_n, big.mark = ','))\n\t\t} else {\n\t\t\ttitle <- paste0('No n found where p < ', attr(x, 'sig_level'), ' and power > ', pow)\n\t\t}\n\t}\n\n\tp <- p +\n\t\tylim(c(0, 1)) +\n\t\tylab('') +\n\t\txlab('Sample Size') +\n\t\tggtitle(title,\n\t\t\t\tsubtitle = paste0('Probabilities: ', paste0(round(attr(x, 'probs'), digits = digits), collapse = ', ')))\n\n\treturn(p)\n}\n```\n:::\n\n\n\n\n\nReturning to our example above where the cell proportions are 33%, 25%, and 42%, we would need $n \\ge 130$ to reject the *null* hypothesis.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncsp1 <- chi_squared_power(probs =  c(.33, .25, .42))\ncsp1[csp1$sig,]$n |> min(na.rm = TRUE) # Smallest n that results in p < 0.05\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 130\n```\n\n\n:::\n\n```{.r .cell-code}\nplot(csp1)\n```\n\n::: {.cell-output-display}\n![](2025-03-04-chi_squared_sample_sizes_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\n\nIn the next example we have much smaller differences between the cells with 25%, 25%, 24%, and 26%. In this example $n \\ge 9,710$ before rejecting the *null* hypothesis.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncsp3 <- chi_squared_power(probs = c(.25, .25, .24, .26), max_n = 20000)\ncsp3[csp3$sig,]$n |> min(na.rm = TRUE) # Smallest n that results in p < 0.05\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 9710\n```\n\n\n:::\n\n```{.r .cell-code}\nplot(csp3)\n```\n\n::: {.cell-output-display}\n![](2025-03-04-chi_squared_sample_sizes_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\n\nThis function will work with two-dimensional data as well (i.e. across two variables). The following example from Agresti (2007) looks at the political affiliation across sex (see the help documentation for `chisq.test()`.).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nM <- as.table(rbind(c(762, 327, 468), c(484, 239, 477)))\ndimnames(M) <- list(gender = c(\"Femal\", \"Male\"),\n\t\t\t\t\tparty = c(\"Democrat\", \"Independent\", \"Republican\"))\nM\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       party\ngender  Democrat Independent Republican\n  Femal      762         327        468\n  Male       484         239        477\n```\n\n\n:::\n\n```{.r .cell-code}\nsum(M)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2757\n```\n\n\n:::\n:::\n\n\n\n\nThe chi-squared test suggests we should reject the *null* hypothesis test.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchisq.test(M)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's Chi-squared test\n\ndata:  M\nX-squared = 30.07, df = 2, p-value = 2.954e-07\n```\n\n\n:::\n\n```{.r .cell-code}\nDescTools::CramerV(M) # Effect size\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.1044358\n```\n\n\n:::\n\n```{.r .cell-code}\nDescTools::power.chisq.test(n = sum(M),\n\t\t\t\t\t\t\tw = DescTools::CramerV(M),\n\t\t\t\t\t\t\tdf = min(dim(M)) - 1,\n\t\t\t\t\t\t\tsig.level = 1 - sig_level)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n     Chi squared power calculation \n\n              w = 0.1044358\n              n = 2757\n             df = 1\n      sig.level = 0.05\n          power = 0.9997872\n\nNOTE: n is the number of observations\n```\n\n\n:::\n:::\n\n\n\n\nAgresti had a sample size of 2757, but we can ask the question what is the minimum sample size would they need to detect statistical significance? First, we convert the counts to proportions, then we can use the `chi_squared_power()` function to find the minimum sample size to reject the *null* hypothesis test.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nM_prob <- M / sum(M) # Convert the counts to percentages\ncsp4 <- chi_squared_power(probs = M_prob)\nplot(csp4)\n```\n\n::: {.cell-output-display}\n![](2025-03-04-chi_squared_sample_sizes_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\n\nFor a more robust application for estimating power for many statistical tests, check out the [pwsrr R package](https://cran.r-project.org/web/packages/pwrss/index.html) and corresponding [Shiny application](https://pwrss.shinyapps.io/index/).\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}